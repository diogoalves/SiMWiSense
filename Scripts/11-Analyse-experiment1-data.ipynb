{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "data = np.load('../Output/CompareFineGrainedModelsSingleVsMultiple/fine_grained_trainedon_Classroom_m1_242.h5_gradcam_and_embeddings.npz')\n",
    "gradcam1 = data['gradcam']\n",
    "embeddings1 = data['embeddings']\n",
    "csv1 = pd.read_csv('../Output/CompareFineGrainedModelsSingleVsMultiple/fine_grained_trainedon_Classroom_m1_242.h5_output.csv')\n",
    "\n",
    "data = np.load('../Output/CompareFineGrainedModelsSingleVsMultiple/fine_grained_trainedon_ClassroomOffice_m1m2m3_242-fixed.h5_gradcam_and_embeddings.npz')\n",
    "gradcam2 = data['gradcam']\n",
    "embeddings2 = data['embeddings']\n",
    "csv2 = pd.read_csv('../Output/CompareFineGrainedModelsSingleVsMultiple/fine_grained_trainedon_ClassroomOffice_m1m2m3_242-fixed.h5_output.csv')\n",
    "\n",
    "print('Grad-CAM shape:', gradcam1.shape, gradcam2.shape)\n",
    "print('Embeddings shape:', embeddings1.shape, embeddings2.shape)\n",
    "print('CSV shape:', csv1.shape, csv2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57174a",
   "metadata": {},
   "source": [
    "----\n",
    "# Predictions confidence distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfde5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['A', 'C', 'P', 'S']\n",
    "csvs = [csv1, csv2]\n",
    "titles = ['Classroom-m1', 'Classroom-m1m2m3']\n",
    "index = 0\n",
    "for csv in csvs:\n",
    "  right_predictions = csv.loc[csv['right_prediction']==True, 'predicted_prob'].to_list()\n",
    "  false_predictions = csv.loc[csv['right_prediction']==False, 'predicted_prob'].to_list()\n",
    "  util.plot_prediction_confidence_distribution(right_predictions, false_predictions, title=f'{titles[index]} all labels')\n",
    "  for label in labels:\n",
    "    right_predictions = csv.loc[(csv['right_prediction']==True) & (csv['label']==label), 'predicted_prob'].to_list()\n",
    "    false_predictions = csv.loc[(csv['right_prediction']==False) & (csv['label']==label), 'predicted_prob'].to_list()\n",
    "    util.plot_prediction_confidence_distribution(right_predictions, false_predictions, title=f'{titles[index]} {label}')\n",
    "  index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f46642",
   "metadata": {},
   "source": [
    "**Anotações**\n",
    "- A distribuições da confinça das predições varia bastante na classe P (reading) entre os modelos. Talvez esse gráfico seja útil para mostra para uma pessoa leiga que o modelo 2 tem mais certeza tanto na hora de prever certo e errado para essa classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8674dd4",
   "metadata": {},
   "source": [
    "----\n",
    "# GradCam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4336713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2113952/4001204729.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  csv_merged['both_right_prediction'] = csv_merged['both_right_prediction'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "csv_merged = pd.merge(left=csv1, right=csv2, how='inner', on='filename', suffixes=('_m1', '_m1m2m3'))\n",
    "csv_merged.loc[(csv_merged['right_prediction_m1']==True) & (csv_merged['right_prediction_m1m2m3']==True), 'both_right_prediction'] = True\n",
    "csv_merged['both_right_prediction'] = csv_merged['both_right_prediction'].fillna(False)\n",
    "\n",
    "# Create a sort key for the filenames\n",
    "csv_merged['sort_key'] = csv_merged['filename'].str.split('_', expand=True)[0] + '_' + csv_merged['filename'].str.split('_', expand=True)[1] + '_' + csv_merged['filename'].str.split('_', expand=True)[2].str.split('.', expand=True)[0].str.zfill(5)\n",
    "\n",
    "\n",
    "# Create a new index based on the sorted filenames\n",
    "csv_merged.sort_values(by='sort_key', inplace=True)\n",
    "csv_merged = csv_merged.reset_index()\n",
    "csv_merged.rename(columns={'index': 'gradcam_index'}, inplace=True)\n",
    "\n",
    "\n",
    "# Constants\n",
    "activities = {\n",
    "  'A': 'Push forward',\n",
    "  'C': 'Hands up and down',\n",
    "  'P': 'Reading',\n",
    "  'S': 'Writing'\n",
    "}\n",
    "\n",
    "def compute_iou(cam1, cam2, threshold=0.2):\n",
    "  cam1_bin = cam1 > threshold\n",
    "  cam2_bin = cam2 > threshold\n",
    "  intersection = np.logical_and(cam1_bin, cam2_bin).sum(axis=(1,2))\n",
    "  union = np.logical_or(cam1_bin, cam2_bin).sum(axis=(1,2))\n",
    "  iou = np.divide(intersection, union, out=np.zeros_like(intersection, dtype=float), where=union != 0)\n",
    "  return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ee214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   7,   8,  14,  19,  24,  39,  40,  53,  63,  66,  70,  71,\n",
       "        72,  84, 121, 128, 144, 147, 157, 159, 166, 171, 177, 178, 195,\n",
       "       216, 217, 220, 235, 244, 246, 247, 251, 254, 256, 277, 293, 360,\n",
       "       371, 372, 375, 398, 429, 459, 465, 468, 475, 481, 489, 493, 494,\n",
       "       497, 501, 514, 527, 565, 567, 572, 610, 611, 612])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = csv_merged.loc[(csv_merged['both_right_prediction']==True) & (csv_merged['label_m1']=='P')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fa040460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99, 160, 161, 163, 227, 228, 233, 239, 240, 243, 244, 245, 247,\n",
       "       251, 252, 253, 254, 257, 260, 382, 478, 480, 488, 499, 554])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_threshold = np.percentile(iou, 96)\n",
    "iou_top_indexes = np.where(iou >= iou_threshold)[0]\n",
    "iou_top_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "95c64f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def plot_gradcam(gradcam1, gradcam2, csv_merged, label):\n",
    "  subset = csv_merged.loc[(csv_merged['both_right_prediction']==True) & (csv_merged['label_m1']==label)]\n",
    "  rows = len(subset) // 3\n",
    "  # rows = 10\n",
    "  cols = 6\n",
    "\n",
    "  # Compute similarties\n",
    "  # Cosine similarity\n",
    "  gradcam1flatten = gradcam1[subset['gradcam_index']].reshape(len(subset), -1)\n",
    "  gradcam2flatten = gradcam2[subset['gradcam_index']].reshape(len(subset), -1)\n",
    "  cos_sim = cosine_similarity(gradcam1flatten, gradcam2flatten)[0, :]\n",
    "  cos_sim_threshold = np.percentile(cos_sim, 95)\n",
    "  com_sim_top_indexes = np.where(cos_sim > cos_sim_threshold)[0]\n",
    "  # IoU @ 0.2\n",
    "  iou = compute_iou(gradcam1[subset['gradcam_index']], gradcam2[subset['gradcam_index']], threshold=0.2)\n",
    "  iou_threshold = np.percentile(iou, 96)\n",
    "  iou_top_indexes = np.where(iou >= iou_threshold)[0]\n",
    "\n",
    "  fig, axs = plt.subplots(rows, cols, figsize=(15, rows), dpi=110)\n",
    "\n",
    "  for row in tqdm(range(rows)):\n",
    "    for i in range(3):  # 3 pares de imagens por linha\n",
    "      col_base = 2 * i\n",
    "      index = row + i * rows\n",
    "      filename = subset.iloc[index]['filename']\n",
    "      filename = f'{filename[0]}/{filename[14:-4]}'\n",
    "      gradcam_index = subset.iloc[index]['gradcam_index']\n",
    "      predicted_prob_m1 = subset.iloc[index]['predicted_prob_m1'] * 100\n",
    "      predicted_prob_m1m2m3 = subset.iloc[index]['predicted_prob_m1m2m3'] * 100\n",
    "\n",
    "      # GradCAM 1\n",
    "      resized = cv2.resize(gradcam1[gradcam_index], (242, 50))\n",
    "      axs[row, col_base].imshow(resized, cmap='jet')\n",
    "      axs[row, col_base].set_xlabel(f'{predicted_prob_m1:.2f}%', fontsize=9)\n",
    "      axs[row, col_base].set_xticks([])\n",
    "      axs[row, col_base].set_yticks([])\n",
    "      axs[row, col_base].set_ylabel(filename, fontsize=9, fontweight='bold')\n",
    "\n",
    "      # GradCAM 2\n",
    "      resized = cv2.resize(gradcam2[gradcam_index], (242, 50))\n",
    "      axs[row, col_base + 1].imshow(resized, cmap='jet')\n",
    "\n",
    "      label2 = f'{predicted_prob_m1m2m3:.2f}%'\n",
    "      if index in com_sim_top_indexes:\n",
    "        label2 = f'{label2} (Top95%CosSim)'\n",
    "      if index in iou_top_indexes:\n",
    "        label2 = f'{label2} (Top96%IoU)'\n",
    "\n",
    "        \n",
    "      axs[row, col_base + 1].set_xlabel(label2, fontsize=7)\n",
    "      axs[row, col_base + 1].set_xticks([])\n",
    "      axs[row, col_base + 1].set_yticks([])\n",
    "\n",
    "      if row == 0:\n",
    "        axs[row, col_base].set_title(f'Classroom-m1', fontsize=10, fontweight='bold')\n",
    "        axs[row, col_base + 1].set_title(f'ClassroomOffice-m1m2m3', fontsize=10, fontweight='bold')\n",
    "\n",
    "  line1 = Line2D([0.335, 0.335], [0.0, 1.0], color='black', linewidth=2, linestyle='-')\n",
    "  line2 = Line2D([0.665, 0.665], [0.0, 1.0], color='black', linewidth=2, linestyle='-')\n",
    "  fig.add_artist(line1)\n",
    "  fig.add_artist(line2)\n",
    "\n",
    "  # Tamanho total da figura em polegadas × DPI = altura em pixels\n",
    "  fig_height_px = fig.get_size_inches()[1] * fig.dpi\n",
    "  pixels_reserved = 10  # por exemplo\n",
    "\n",
    "  # Converter pixels para fração da altura\n",
    "  top_fraction = 1 - pixels_reserved / fig_height_px\n",
    "\n",
    "  # Aplicar no tight_layout\n",
    "  plt.tight_layout(rect=[0, 0, 1, top_fraction])\n",
    "  plt.suptitle(f'Grad-CAM Heatmaps for Classroom-m1 and ClassroomOffice-m1m2m3 Models Label={label} ({activities[label]})', fontsize=10, fontweight='bold', y=top_fraction)\n",
    "\n",
    "  save_path = f'../Output/CompareFineGrainedModelsSingleVsMultiple/gradcam_heatmaps_{label}.png'\n",
    "  plt.savefig(save_path, bbox_inches='tight', dpi=110)\n",
    "  plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "51382fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:00<00:00, 365.15it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_gradcam(gradcam1, gradcam2, csv_merged, label='P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8c6ec4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Grad-CAM for label: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:01<00:00, 364.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Grad-CAM for label: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:01<00:00, 358.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Grad-CAM for label: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:00<00:00, 353.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Grad-CAM for label: S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [00:00<00:00, 339.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for label in activities.keys():\n",
    "  print(f'Plotting Grad-CAM for label: {label}')\n",
    "  plot_gradcam(gradcam1, gradcam2, csv_merged, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f08cf0",
   "metadata": {},
   "source": [
    "---- \n",
    "# t-SNE and UMAP of GradCams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbac76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "activities = {\n",
    "  'A': 'Push forward',\n",
    "  'C': 'Hands up and down',\n",
    "  'P': 'Reading',\n",
    "  'S': 'Writing'\n",
    "}\n",
    "\n",
    "# Correct predictions\n",
    "right1 = csv1.loc[csv1['right_prediction'] == True]\n",
    "right2 = csv2.loc[csv2['right_prediction'] == True]\n",
    "\n",
    "# Add GradCam indexes\n",
    "right1.reset_index(inplace=True)\n",
    "right1.rename(columns={'index': 'gradcam_index'}, inplace=True)\n",
    "right2.reset_index(inplace=True)\n",
    "right2.rename(columns={'index': 'gradcam_index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(subset, gradcam, title='', output_file=None, perplexity=30):\n",
    "  X = gradcam[subset['gradcam_index'], :].reshape(len(subset), -1)\n",
    "\n",
    "  labels = subset['label'].tolist()\n",
    "  label_encoder = LabelEncoder()\n",
    "  numeric_labels = label_encoder.fit_transform(labels)\n",
    "  class_names = label_encoder.classes_\n",
    "  class_names = np.array([activities[classname] for classname in class_names ])\n",
    "\n",
    "  colormap = 'tab10'\n",
    "  cmap = plt.get_cmap(colormap, len(class_names))\n",
    "\n",
    "  tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "  X_embedded = tsne.fit_transform(X)\n",
    "  x, y = X_embedded[:, 0], X_embedded[:, 1]\n",
    "\n",
    "  fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "  ax[0].scatter(x, y, c=numeric_labels, cmap=cmap, s=5)\n",
    "  ax[0].set_title(title)\n",
    "  ax[0].set_xlabel('t-SNE Component 1')\n",
    "  ax[0].set_ylabel('t-SNE Component 2')\n",
    "  ax[0].grid(True)\n",
    "\n",
    "  # Polar\n",
    "  r = np.sqrt(x**2 + y**2)\n",
    "  theta = np.arctan2(y, x)\n",
    "  ax[1].scatter(theta, r, c=numeric_labels, cmap=colormap, s=5)\n",
    "  ax[1].set_title(f'{title} (polar)')\n",
    "  ax[1].set_xlabel('radius')\n",
    "  ax[1].set_ylabel('theta')\n",
    "\n",
    "  plt.tight_layout()\n",
    "\n",
    "  legend_handles = []\n",
    "  for i, class_name in enumerate(class_names):\n",
    "      # Use the same cmap to get the color for each class\n",
    "      color = cmap(i)\n",
    "      legend_handles.append(plt.Line2D([0], [0], marker='o', color='w', label=class_name,\n",
    "                                      markersize=10, markerfacecolor=color))\n",
    "\n",
    "  plt.legend(handles=legend_handles, loc='upper right', bbox_to_anchor=(1.15, 1), fontsize=8)\n",
    "\n",
    "\n",
    "  if output_file is not None:\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_umap(subset, gradcam, title='', output_file=None, n_neighbors=15, min_dist=0.1, low_memory=False):\n",
    "  X = gradcam[subset['gradcam_index'], :].reshape(len(subset), -1)\n",
    "\n",
    "  labels = subset['label'].tolist()\n",
    "\n",
    "  label_encoder = LabelEncoder()\n",
    "  numeric_labels = label_encoder.fit_transform(labels)\n",
    "  class_names = label_encoder.classes_\n",
    "  class_names = np.array([activities[classname] for classname in class_names ])\n",
    "\n",
    "  mapper = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, low_memory=low_memory).fit(X)\n",
    "  umap.plot.points(mapper, labels=class_names[numeric_labels], cmap='tab10')\n",
    "  plt.title(title)\n",
    "  if output_file is not None:\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29efe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(right1, gradcam1, title='t-SNE for Classroom-m1 Correct GradCams', perplexity=5, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/tsne_Classroom_m1_correct_gradcam.png')\n",
    "plot_tsne(right2, gradcam2, title='t-SNE for ClassroomOffice-m1m2m3 Correct GradCams', perplexity=5, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/tsne_ClassroomOffice_m1m2m3_correct_gradcam.png')\n",
    "plot_umap(right1, gradcam1, title='UMAP for Classroom-m1 Correct GradCams', n_neighbors=10, min_dist=0.7, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/umap_Classroom_m1_correct_gradcam.png')\n",
    "plot_umap(right2, gradcam2, title='UMAP for ClassroomOffice-m1m2m3 Correct GradCams', n_neighbors=10, min_dist=0.7, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/umap_ClassroomOffice_m1m2m3_correct_gradcam.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e217137",
   "metadata": {},
   "source": [
    "----\n",
    "# t-SNE and UMAP of Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64972f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(right1, embeddings1, title='t-SNE for Classroom-m1 Correct Embeddings', perplexity=5, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/tsne_Classroom_m1_correct_embeddings.png')\n",
    "plot_tsne(right2, embeddings2, title='t-SNE for ClassroomOffice-m1m2m3 Correct Embeddings', perplexity=5, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/tsne_ClassroomOffice_m1m2m3_correct_embeddings.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap(right1, embeddings1, title='UMAP for Classroom-m1 Correct Embeddings', n_neighbors=10, min_dist=0.7, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/umap_Classroom_m1_correct_embeddings.png', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap(right2, embeddings2, title='UMAP for ClassroomOffice-m1m2m3 Correct Embeddings', n_neighbors=10, min_dist=0.7, output_file='../Output/CompareFineGrainedModelsSingleVsMultiple/umap_ClassroomOffice_m1m2m3_correct_embeddings.png', low_memory=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
